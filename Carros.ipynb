{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Carros.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_WIB_f1z4hC9OkBcuUBr9ZhnblHVkS7s",
      "authorship_tag": "ABX9TyO1292jn6a9DwjTbbR510s1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loaizanicolas1912/Portafolio-ML/blob/master/Carros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6gw7Ko6ptE_"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D, Flatten, Dropout,BatchNormalization, AveragePooling2D\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "from keras.callbacks import History\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MsmGrYVrNOy"
      },
      "source": [
        "train_data = '/content/drive/My Drive/Cars/Train'\r\n",
        "validation_data = '/content/drive/My Drive/Cars/Validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDM-yEkxrifi"
      },
      "source": [
        "#PARAMETROS\r\n",
        "altura, longitud = 100, 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdSWufodt_ul"
      },
      "source": [
        "#prepro\r\n",
        "entrenamiento_data_gen = ImageDataGenerator(\r\n",
        "    rescale=1/255.0,\r\n",
        "    #zoom_range=0.2,\r\n",
        ")\r\n",
        "\r\n",
        "validation_data_gen = ImageDataGenerator(\r\n",
        "    rescale=1/255.0,\r\n",
        "    #horizontal_flip=True,\r\n",
        "    #shear_range=0.4,\r\n",
        "    #zoom_range=0.5,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyPvPH8FvDHy",
        "outputId": "01b99f86-1726-41e7-9224-a03721592cbd"
      },
      "source": [
        "imagen_entrenamiento = entrenamiento_data_gen.flow_from_directory(\r\n",
        "    train_data,\r\n",
        "    target_size=(altura, longitud),\r\n",
        "    batch_size = 32,\r\n",
        "    class_mode='categorical'\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16241 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQDOnlOVuqxj",
        "outputId": "30513b3c-c620-4f2d-b651-7cd1f7b8b8c4"
      },
      "source": [
        "imagen_validation = validation_data_gen.flow_from_directory(\r\n",
        "    validation_data,\r\n",
        "    target_size=(altura, longitud),\r\n",
        "    batch_size = 32,\r\n",
        "    class_mode='categorical'\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1036 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYo4Vvu9Diyz",
        "outputId": "b3bafcd7-0b9f-4210-e35d-8935b673b9ec"
      },
      "source": [
        "print(imagen_entrenamiento.class_indices)\r\n",
        "print(imagen_validation.class_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Camioneta': 0, 'Car': 1, 'articulated': 2, 'bus': 3, 'pedestrian': 4}\n",
            "{'Camioneta': 0, 'Car': 1, 'articulated': 2, 'bus': 3, 'pedestrian': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72xT-Sohwxyo"
      },
      "source": [
        "Model3 = Sequential()\r\n",
        "Model3.add(Conv2D(filters=32,kernel_size=4,padding='same', activation='relu', input_shape=([100,100,3])))\r\n",
        "#Model3.add(BatchNormalization())\r\n",
        "Model3.add(AveragePooling2D())\r\n",
        "Model3.add(Conv2D(filters=32,kernel_size=4,padding='same',activation='relu'))\r\n",
        "#Model3.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'))\r\n",
        "Model3.add(AveragePooling2D())\r\n",
        "Model3.add(Conv2D(filters=16,kernel_size=4,padding='valid',activation='relu'))\r\n",
        "#Model3.add(Conv2D(filters=64,kernel_size=2,padding='same',activation='relu'))\r\n",
        "Model3.add(AveragePooling2D())\r\n",
        "Model3.add(Flatten())\r\n",
        "Model3.add(Dense(128,activation='relu'))\r\n",
        "Model3.add(Dropout(0.7))\r\n",
        "Model3.add(Dense(32,activation='relu'))\r\n",
        "Model3.add(Dropout(0.7))\r\n",
        "Model3.add(Dense(32,activation='relu'))\r\n",
        "Model3.add(Dropout(0.2))\r\n",
        "Model3.add(Dense(5,activation='softmax'))\r\n",
        "\r\n",
        "Model3.compile(loss='categorical_crossentropy', optimizer=Adam(0.0006), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A8tqixTmjQg",
        "outputId": "52736fb4-2e54-49a4-9143-f2ae089b49d4"
      },
      "source": [
        "Model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 100, 100, 32)      1568      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average (None, 50, 50, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 50, 50, 32)        16416     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_7 (Average (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 22, 22, 16)        8208      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_8 (Average (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1936)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               247936    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 279,477\n",
            "Trainable params: 279,477\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4GS84TjgZUX",
        "outputId": "c2cd4db5-d86d-49a9-83fa-f87337e94435"
      },
      "source": [
        "#steps_per_epoch= ejemplosTra/batch_Size\r\n",
        "#validation_data = ejemplosVa/batch_Size\r\n",
        "\r\n",
        "checkpoint_path = '/content/drive/My Drive/Modeloscheck'\r\n",
        "keras_callbacks   = [\r\n",
        "      ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min')\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Monitor = EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\r\n",
        "\r\n",
        "Model3.fit(imagen_entrenamiento,\r\n",
        "          batch_size=32,\r\n",
        "          steps_per_epoch=250,\r\n",
        "          epochs=50,\r\n",
        "          validation_data=imagen_validation,        \r\n",
        "          validation_steps=20, \r\n",
        "          callbacks=[keras_callbacks])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 1.6101 - accuracy: 0.2307 - val_loss: 1.6116 - val_accuracy: 0.2141\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 1.6000 - accuracy: 0.2459 - val_loss: 1.6050 - val_accuracy: 0.2109\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 1.5823 - accuracy: 0.2717 - val_loss: 1.4545 - val_accuracy: 0.3625\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 1.4410 - accuracy: 0.3913 - val_loss: 1.2821 - val_accuracy: 0.5109\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 1.3114 - accuracy: 0.4833 - val_loss: 1.1601 - val_accuracy: 0.5219\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 1.1517 - accuracy: 0.5503 - val_loss: 0.9456 - val_accuracy: 0.6297\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 1.0601 - accuracy: 0.5941 - val_loss: 0.8700 - val_accuracy: 0.6719\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.9438 - accuracy: 0.6435 - val_loss: 0.7715 - val_accuracy: 0.7172\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.8725 - accuracy: 0.6718 - val_loss: 0.7606 - val_accuracy: 0.7234\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.8485 - accuracy: 0.6912 - val_loss: 0.7498 - val_accuracy: 0.7109\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.7561 - accuracy: 0.7234 - val_loss: 0.6712 - val_accuracy: 0.7469\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.7311 - accuracy: 0.7384 - val_loss: 0.6552 - val_accuracy: 0.7500\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.7061 - accuracy: 0.7489 - val_loss: 0.6585 - val_accuracy: 0.7594\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.6923 - accuracy: 0.7542 - val_loss: 0.6403 - val_accuracy: 0.7547\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.6266 - accuracy: 0.7757 - val_loss: 0.7062 - val_accuracy: 0.7563\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.5901 - accuracy: 0.7996 - val_loss: 0.6687 - val_accuracy: 0.7516\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.5965 - accuracy: 0.7876 - val_loss: 0.6255 - val_accuracy: 0.7578\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 16s 64ms/step - loss: 0.5616 - accuracy: 0.8001 - val_loss: 0.6262 - val_accuracy: 0.7484\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.5795 - accuracy: 0.8000 - val_loss: 0.5979 - val_accuracy: 0.7719\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.5264 - accuracy: 0.8138 - val_loss: 0.6927 - val_accuracy: 0.7531\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.5246 - accuracy: 0.8217 - val_loss: 0.6125 - val_accuracy: 0.7656\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.4947 - accuracy: 0.8289 - val_loss: 0.6302 - val_accuracy: 0.7609\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.4664 - accuracy: 0.8423 - val_loss: 0.6582 - val_accuracy: 0.7641\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.4460 - accuracy: 0.8501 - val_loss: 0.5593 - val_accuracy: 0.7844\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.4564 - accuracy: 0.8426 - val_loss: 0.6551 - val_accuracy: 0.7797\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.4466 - accuracy: 0.8456 - val_loss: 0.6878 - val_accuracy: 0.7719\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.4549 - accuracy: 0.8477 - val_loss: 0.6243 - val_accuracy: 0.7891\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.4545 - accuracy: 0.8483 - val_loss: 0.8301 - val_accuracy: 0.7672\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.4104 - accuracy: 0.8627 - val_loss: 0.6043 - val_accuracy: 0.8016\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.4004 - accuracy: 0.8680 - val_loss: 0.5670 - val_accuracy: 0.8141\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.3900 - accuracy: 0.8754 - val_loss: 0.6869 - val_accuracy: 0.7719\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.3814 - accuracy: 0.8635 - val_loss: 0.6351 - val_accuracy: 0.7922\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.3695 - accuracy: 0.8817 - val_loss: 0.5706 - val_accuracy: 0.7922\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.3787 - accuracy: 0.8717 - val_loss: 0.7193 - val_accuracy: 0.7937\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.3760 - accuracy: 0.8823 - val_loss: 0.5969 - val_accuracy: 0.8000\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.3615 - accuracy: 0.8797 - val_loss: 0.5842 - val_accuracy: 0.8062\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.3545 - accuracy: 0.8813 - val_loss: 0.5871 - val_accuracy: 0.7891\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.3742 - accuracy: 0.8740 - val_loss: 0.6232 - val_accuracy: 0.7859\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.3097 - accuracy: 0.8961 - val_loss: 0.5375 - val_accuracy: 0.8172\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Modeloscheck/assets\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.3489 - accuracy: 0.8847 - val_loss: 0.5740 - val_accuracy: 0.8156\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.3305 - accuracy: 0.8886 - val_loss: 0.6382 - val_accuracy: 0.8031\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.3389 - accuracy: 0.8864 - val_loss: 0.6360 - val_accuracy: 0.8031\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.3406 - accuracy: 0.8860 - val_loss: 0.6243 - val_accuracy: 0.8047\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.3014 - accuracy: 0.9000 - val_loss: 0.7209 - val_accuracy: 0.7844\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.3081 - accuracy: 0.8922 - val_loss: 0.6123 - val_accuracy: 0.8109\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.3332 - accuracy: 0.8881 - val_loss: 0.6815 - val_accuracy: 0.8031\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.3268 - accuracy: 0.8912 - val_loss: 0.6485 - val_accuracy: 0.8047\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.3201 - accuracy: 0.8945 - val_loss: 0.6484 - val_accuracy: 0.8188\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.2786 - accuracy: 0.9074 - val_loss: 0.7124 - val_accuracy: 0.8094\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.3134 - accuracy: 0.9012 - val_loss: 0.6218 - val_accuracy: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdecc6fe860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}